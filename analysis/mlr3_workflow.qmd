---
title: "mlr3 Workflow"
author: "Julia Lober"
format: html
editor: visual
params:
  data_dir:
    label: Data Directory
    value: /Users/julialober/Documents/terrainworks/code/sandbox/data/
    input: text
  training_data:
    label: Training data .Rdata file
    value:  sample_umpqua.Rdata
    input: text
  points:
    label: Training data points
    value:  DeanCr/DeanCr_Initiation_Points.shp
    input: text
  dem:
    label: Training data dem
    value:  DeanCr/elev_deancr.flt
    input: text
---

```{r setup}
#| echo: false
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  error = FALSE
)
```

```{r}
#| echo: false
load(paste0(params$data_dir, params$training_data))
pnts <- vect(paste0(params$data_dir, params$points))
dem <- rast(paste0(params$data_dir, params$dem))
```

## Workflow for the mlr3 package

This is a document where I work out how to use the `mlr3` package. According to Dan, this is package ecosystem has been taking over for `caret`.

```{r load, include = FALSE}
library(mlr3)
library(mlr3spatial)
library(mlr3spatiotempcv)
library(mlr3learners)
# Packages for models - change these based on what type of model you build
library(glmnet)
```

Major points for the `mlr3` package include the different nomenclature. The data used to train a model is referred to a `task` and the model being trained is referred to as a `learner`.

This is a general workflow for any type of model. Another major difference between `mlr3` and `caret` is the names of the model types. The `mlr3learners` package provides the following model types.

```{r}
mlr_learners
```

## Step 1. Creating a task and a learner

Our task leaves out the `id` column in the sample_pnts data frame, as it will not be relevant information for the model! Specifying the target says what we want the learner to predict - for us, this is the `class` which is positive for landslide initiation points.

```{r}
task <- as_task_classif(x = sample_pnts[, 2:8], id = "landslide_init", target = "class")
head(task)
```

The learner is created based on what type of model we want to train. See above for a list of learners that are available (and keep in mind that you could load `mlr3extralearners` for an even bigger selection). We are interested in classification learners, since the input is categorized into two different classes.

```{r}
learner <- lrn("classif.log_reg", predict_type = "prob")
print(learner)
```

As an experiment, we could train and predict using all of the data. This is bad practice in machine learning but can be an interesting baseline and will help me figure out the syntax.

```{r}
learner$train(task)
print(learner$model)
```

For the generalized linear model (`glmnet`), we need to manually set lambda. This parameter cannot be tuned, so

```{r}
predicted <- learner$predict(task)
print(predicted)
```

Next, we can take a general look at some performance measures.

```{r}
head(as.data.table(mlr_measures))
```

Print some of these metrics.

`classif.acc` is the accuracy of the model and `classif.ce` is the error. These should always be inverses of each other.

`classif.auc` is the area under the ROC curve. Since we are interested more in the probability of a yes (landslide initiation) than simply classification into binary classes, this measure is a bit more useful.

```{r}
scores <- predicted$score(msrs(c("classif.acc", "classif.ce", "classif.auc")))
print(scores)

conf_matrix <- predicted$confusion
print(conf_matrix)
```

## Step 2. Add a resampling method

For any machine learning

```{r}

```
