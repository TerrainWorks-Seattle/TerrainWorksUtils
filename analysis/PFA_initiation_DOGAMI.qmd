---
title: "Steep-slopes modeling for the Private Forest Accord"
author: "Dan Miller and Julia Lober"
format: 
  html:
    toc: true
    toc-float: true
    toc-depth: 3
    number-sections: true
    code-folding: hide
    theme: readable
    code-fold: true
    code-overflow: scroll
date: May 24, 2023
editor: visual
number-sections: true
bibliography: references.bib
editor_options: 
  chunk_output_type: console
---

```{r load, include = FALSE}
library(TerrainWorksUtils)
library(terra)
library(stringr)
library(car)
library(ggplot2)
library(patchwork)
library(dplyr)
library(mlr3verse)
library(iml)
library(colorspace)
library(RColorBrewer)
```

# Introduction

In steep-land regions of Oregon, landsliding of shallow soils that subsequently evolve into a debris flow are a primary process by which sediment and wood is carried from hillslopes to valley floors and stream channels [@Swanson1982; @benda1997; @reeves2003a]. The deposits formed by these events profoundly influence valley floor and channel morphology [@benda1990a; @bigelow2007]. At any single failure site, the frequency of such events is rare, with recurrence intervals spanning thousands of years [@benda1987]. There are many such sites, however, so when integrated over a channel network, these landslides and debris flows are important drivers of the disturbance regime that acts, in part, to set the spatial and temporal distribution of habitat types across a basin [@bendaEtal1998; @rieman2006a]. A goal of forest management is, therefore, to avoid doing things that will change that disturbance regime [@penaluna2018a]. This is reflected in the Private Forest Accord's approach to timber harvest on steep slopes [Chapter 3 and Appendix B, @odf2022], for which harvest prescriptions apply to the source areas and traversal corridors of debris flows that might travel to fish-bearing streams. These zones are ranked by the frequency of debris-flow delivery to fish-bearing streams, so that prescriptions can target those zones where timber harvest is most likely to alter the frequency and magnitude of sediment and wood fluxes to those streams.

These source areas and transport corridors are identified for the PFA using models of landslide initiation and debris-flow runout developed by Kelly Burnett and myself with the Coastal Analysis and Modeling Study ([CLAMS](https://www.fsl.orst.edu/clams/)) as described in Miller and Burnett [-@miller2007; -@miller2008] with application of the models described in Burnett and Miller [-@burnett2007]. The original models were calibrated using landslide-initiation locations, debris tracks, and "debris-torrent"-impacted channels that were field surveyed for the [1996 Storm Study](https://www.oregon.gov/odf/Documents/workingforests/monitoring-technical-report-04.pdf) by the Oregon Department of Forestry (ODF) [@robison1999] and digitized to 10-meter line-trace DEM base maps. Several factors motivate a re-calibration and re-examination of these models.

-   Recent work by the Oregon Department of Geology and Mineral Resources (DOGAMI) [[Special Paper 53](https://www.oregongeology.org/pubs/sp/SP-53/p-SP-53.htm), @burns2022] now provides an inventory of landslide initiation points and debris-flow-runout tracks with a greater geographic and temporal range than available from the 1996 Storm Study,

-   high-resolution DEMs derived from lidar are now available for much of Oregon (<https://www.oregongeology.org/lidar/>), and

-   statistical methods and analysis tools have progressed considerably in the last 15 years.

The Miller-Burnett models identify the channels susceptible to direct impacts from debris flows originating upslope and delineate the source areas for those debris flows. Although the initiation and evolution of a landslide into a debris flow is a continuous process, the models examine landslide initiation and runout separately. This is because initiation and runout involve different sets of physical processes influenced by different sets of environmental factors. An empirical approach is used for both cases, in which statistical models are calibrated using observed landslide initiation sites and debris-flow tracks, but with the choice of explanatory variables (also called the independent variables or predictors) based on current understanding of the physical processes involved. The models are linked in that the modeled potential for downslope impacts is a function of both initiation probability and runout probability. This document focuses on landslide initiation; a separate document describes the analysis done for debris-flow runout and subsequent analyses that utilize the linked models.

In the realm of forest practices, determination of hazards related to landsliding and debris flows has traditionally relied on field observations and mapping done by experienced professionals. Oregon, for example, provides guidelines for identifying and rating areas susceptible to shallow, rapidly moving landslides ([Forest Practices Technical Note Number 2](https://www.oregon.gov/odf/Documents/workingforests/HighLandslideHazardLocationsTechNote2.pdf) and [Number 6](https://www.oregon.gov/odf/Documents/workingforests/LandslideImpactRatingTechNote6.pdf)). Washington state provides guidance in the Forest Practice Board Manual ([Section 16, Guidelines for Evaluating Potentially Unstable Slopes and Landforms](https://www.dnr.wa.gov/publications/bc_fpb_bmsection16_2022.pdf)). At one point, Lee Benda, I, and several others offered training for field identification and mapping of landslide hazards ([Slope Instability and Forest Land Managers](https://terrainworks.sharefile.com/d-s02d3fbb2b87b4ae687e8d71d0d4ca729)).

So why use a computer model now? Timber-land management seeks to promote both ecologic and economic integrity. Decisions about how to do that in the context of landslides and debris flows invariably involves trade offs between the extent of area where harvest restrictions apply and the area available for timber production. A method or model to quantify those trade offs can provide cost-benefit comparisons to inform decision makers. Once those decisions are made, a consistent method for mapping those areas across landslide-prone regions of Oregon is needed so that timber-land managers can incorporate that information into harvest and road-construction planning and anticipate the consequences for field operations. A computer model can provide a quantitative and consistent method for that mapping. The resulting maps are not necessarily better than those provided through manual mapping; indeed, ground-based observations will still be essential for the final determination of landslide-prone zones because many factors that influence landslide potential cannot be resolved from the remotely sensed data used by computer models. Several factors, however, render a computer model well suited for this task:

-   Manual mapping is subject to the experience and biases of the mapper, so different mappers produce slightly different maps. A computer model can provide a consistent result.

-   Manual mapping requires experienced professionals and takes considerable time and effort. A computer model can provide results for the entire state in a matter of hours. However, development of the model takes considerable time, effort, and expertise.

-   A computer model can incorporate information that is unavailable or difficult to measure through field observations alone. This includes such things as the upslope area contributing shallow subsurface flow for storms of variable duration or the cumulative length of scour zones along all potential upslope debris-flow corridors.

-   A computer model can be designed to make quantitative predictions of probability. Traditional field mapping may offer estimates of high, medium, and low potential, but cannot provide measures of probability. Comparisons of the costs and benefits of different options requires quantitative estimates of the consequences associated with those options, which requires quantitative estimates of the probability of the different potential consequences.

These models are empirical, in that they seek statistical relationships between observed landslide initiation locations and debris-flow corridors with topographic, geologic, and land-cover attributes. Given the large area over which the models must be applied, we use attributes that can be mapped remotely. Modeling strategies span a range from purely physically based (or process-based) models; those based solely on physical explanations of the phenomena modeled (landslide initiation and debris-flow runout), to purely empirical models, based solely on observed associations (locations of landslide initiation sites and channels traversed by debris flows with topographic, geologic, and land-cover attributes). In practice, physical models tend to include empirical components, and likewise empirical models may include and be guided by the underlying physical theory. That is true here; we use the conceptual physics of soil failure to guide our choice of topographic, geologic, and land-cover attributes to compare with landslide and debris-flow locations.

There are physically based models that could be applied here. SHALSTAB [@montgomery1994a; @dietrich2001a], for example, could be used for landslide initiation and a model like [D-Claw](https://dlgeorge.github.io/project/dclaw-project) could be used for runout [see also @iverson2014a]. There are several reasons we chose an empirical approach.

-   With a physically based model, we need to know the physics of what is occurring. There may be things occurring that we do not know about and would not, therefore, be included in a physically based model.

-   Physically based models incorporate simplifications and abstractions of the actual phenomena. This is intrinsic in development of mathematical descriptions of physical phenomena. SHALSTAB, for example, assumes steady-state rainfall onto a planar slope with uniform soil depth; simplifications of actual time-varying rainfall onto slopes with a great deal of topographic convergence and divergence and variable soil depths. This simplification allows for a concise mathematical description of soil failure with which predictions of where landslides are likely to occur can be made, but it will also result in inaccuracies in those predictions.

-   Physically based models require quantitative details about environmental attributes for which we have no information, such as spatial variations in soil depth and texture and the time series of rainfall. Application of these models then requires assumptions about these attributes, which will again result in inaccuracies in model predictions.

For these reasons, physically based models are often used to test and improve our understanding of the physics involved. Errors in predictions point to missing components in the model, or over simplification, or incorrect assumptions. Physically based models are also useful for anticipating the influence of different components in the model. For example, SHALSTAB has been used to show how loss of root strength associated with timber harvest might affect the area subject to landslide initiation [@montgomery1998]. To evaluate effects of root strength with an empirical model requires extensive observations of landslide locations under different forest stand conditions and, even if a correlation is found, we would still be uncertain about the actual cause. But to know if predictions of a physical model are correct or not requires the same data. We need some measure of reality to compare to model predictions, without which we have no idea how much confidence to place in those predictions.

Empirical models come with their own sets of strengths and weaknesses:

-   Empirical models can provide useful prediction even if our understanding is incomplete or the information available is insufficient to fully characterize the processes occurring. For example, to determine the forces acting on a column of soil on a hillslope to calculate the potential for it to fail we need to know the soil depth, but we have no way to actually measure soil depths over regional extents. However, field studies find that soil depths vary systematically with topographic attributes of slope and curvature. These are quantities that we can measure over regional extents using digital elevation models (DEMs) and correlations are found between these topographic attributes and landslide locations. Even though we have not actually measured soil depth, these correlations provide a way to predict where landslides can occur.

-   An empirical model sees only what the data provided it offers. We seek correlations between inventories of mapped landslide locations with environmental attributes. If those inventories provide an incomplete or biased sample of where landslides can occur, then the resulting model will be incomplete or biased.

-   To estimate the effect of incomplete or biased data on predictions of an empirical model, a model can be trained (calibrated) with a portion of the available data and the predictions of that model then tested (compared) against the remaining data. The size of the prediction error on that test portion of the data provides an estimate of model sensitivity to the sample of landslide sites used to build the model. Current analysis protocols repeat that procedure many times using different subsamples for training and testing the model in each iteration. The range of prediction errors provides a measure of model sensitivity with which to gauge the confidence to place in predictions made for locations where landslide inventories for testing the model are not available.

-   The statistical methods used for empirical models use mathematical representations of the relationships between variables. The coefficients for those mathematical equations are adjusted so that the predicted relationship matches the observed relationship as closely possible. For example, we may use a linear equation to relate slope gradient to landslide density. We then adjust the coefficients for that equation to minimize the difference between the predicted and measured densities. The ability of that model to then predict actual landslide densities depends on how well a linear equation represents the actual relationship.

-   We must chose what variables to include in an empirical model. If the variables we chose have strong correlations with landslide location, then an empirical model can work well for predicting where landslides will occur. We therefore strive to include all variables that might correlate with landslide locations. There is also the potential for spurious correlations. A model trained to match random errors or noise in our data might appear to perform well on the training data but will do poorly at predicting landslide locations elsewhere. Separating the signal from the noise inherent in all data sources can be difficult; understanding of the physical basis of the phenomena can guide the choice of variables and mathematical equations used to characterize relationships between variables.

-   The statistical methods used for empirical models can provide a measure of probability. This is the primary reason that we use empirical methods for the steep-slopes analyses performed for the PFA.

Physically based and empirical models are not mutually exclusive. We incorporate elements of both in this analysis. We use the conceptual models on which physical models are built to guide our choice of explanatory variables and we incorporate predictions of a simple physically based model for water flux through hillslope soils as an explanatory variable.

# Landslide initiation.

## Quantitative measures of susceptibility.

For the PFA, we seek to identify source areas and traversal corridors for debris flows that carry sediment and wood to fish-bearing streams and to rank these by the relative frequency of debris-flow occurrence. To do that, for each point on a hillslope, we need to determine the probability for initiation of a debris-flow-triggering landslide and the probability that the subsequent debris flow will travel to a fish-bearing stream. In this document we focus on the probability of initiation; analysis of runout is addressed in a separate document. For this task, we do not need to know anything about when landslides will occur, only where they originate and the relative frequency with which they occur. We use an inventory of mapped landslide locations to do this. Landslide density, the number of landslides per unit area, provides an indicator of where landslides are more or less likely to occur. Higher density indicates higher probability of occurrence. If we observe that landslide density varies with topographic, geologic, and land-cover attributes; statistical methods can be used to build empirical models that specify landslide density as a function of those attributes. Multiplying density by area gives number of landslides; for a DEM cell, multiplying density by cell area gives the probability that a DEM cell contains a landslide initiation point from the landslide inventory. Empirical models that show how attributes of topography, geology, and land cover relate to landslide density thus translate directly to the probability that a DEM cell contains a landslide initiation point. Summing that probability for all DEM cells spanning the study area will return the number of observed landslides. Our goal then is to find models that resolve correlations between landslide density and mapped landscape and environmental attributes.

Debris-flow-triggering landslides occur during rainstorms and the number of landslides increases with increasing rainfall intensity [@turner2010a]

Landslide inventories show us where landslides occur and we use landslide density determined from these inventories as a measure of the likelihood of finding a landslide. To determine how frequently landslides occur requires measures of landslide rate: number per unit area per unit time. Direct measures of rate requires landslide inventories that span not only large areas but also long time periods. Available inventories do not span sufficient time to make reliable measures of rate. Instead, we use landslide density as an indirect measure of rate. An inventory shows how many landslides occurred over some finite period of time. If the spatial variation in landslide density is constant over time, then a one-time measure of that spatial variation is proportional to the spatial variation in landslide rate. We can infer spatial variations in landslide frequency directly from spatial variations in landslide density. If, however, relative differences in density change over time - if, for example, different storms tend to trigger landslides in different types of locations - then we need an inventory that spans sufficient time for a representative sample of storms to occur. The inventories collected by ODF for the 1996 storm study indicated how many landslides occurred during the February and November storms in 1996. The models built using that inventory [@miller2007; @miller2008] reflect the landslide locations associated with those storms. We do not know if different storm events would produce different patterns in the spatial distribution of landslides. The DOGAMI inventory in Special Paper 53 includes landslide events over a longer time span, from 1996 to 2011. This samples a larger range of storm events over a larger geographic area, so it should provide a more representative sample of where landslides occur in Oregon than the 1996 Storm-Study inventory.

A variety of statistical methods can be used to find associations between landslide density and landscape attributes. In our 2007 study [@miller2007], Kelly and I used the "frequency ratio" method, which estimates the change in area and the change in the number of landslides associated with some small change in the attribute of interest. This gives landslide density directly. Classification methods can also be used. These methods seek to classify any location as to whether it is or is not a landslide initiation point. This classification is based on the modeled probability: a probability greater than some specified threshold (e.g., 0.5) is classified as an initiation point. We are interested in the modeled probability, not the classification. Commonly used classification models include logistic regression, random forest, and support vector machines. For any set of attribute values, these models estimate probability as the proportion of sampled sites that contain initiation points included within the data space local to those attribute values.

Within any study area, landslide initiation points occupy a very small proportion of the total area. Consider a 10 km^2^ study area with an average landslide density of 1 landslide/km^2^ (10 landslides total). Using a 1-m lidar-derived DEM, there would be 10 DEM cells with landslide initiation points out of 10 million total cells. Calculations using such an unbalanced sample may reach the limits of computer precision; hence subsamples of the non-initiation DEM cells are typically used for analysis of landslide susceptibility. Because probability is based on the proportion of the total sample composed of initiation points and the number of initiation points is set by the landslide inventory, the modeled probability is proportional to the number of nonlandslide points included in the sample. This is not a problem if the sampled points are representative of the range of conditions over the study area: we are interested in the *spatial variation* of probability, not the magnitude. If we had a larger landslide inventory, for example, with twice as many landslide points over the same study area, landslide densities and modeled probabilities would be twice as large. Likewise, changing the balance of the sample between landslide and nonlandslide points will change the magnitude of the modeled probability, but as long as the samples are representative of conditions over the study area, that will not change the spatial pattern of relative changes. For the PFA analyses, we ultimately translate modeled probabilities to proportions of landslide and debris-flow events, and these proportions are not affected by uniform changes in probability.

We use logistic regression to model initiation probability. The frequency ratio used in the original model works well for one variable, but classification methods are better suited for multiple variables. Logistic regression is more easily interpreted and understood than the other classification methods.

## Predictors

There are several things to consider when choosing predictors to include in an empirical model:

-   [Which landscape attributes are related to landslide density?]{.underline} The ability of a model to resolve variability in landslide potential depends on the degree to which the predictors used in the model are systematically associated with spatial changes in landslide density. We do not want to exclude any potentially informative predictors, but inclusion of correlated, or uninformative, or biased predictors will negatively impact model performance. In a review of the literature, Lima et al. [-@lima2022] counted 116 different predictors that have been applied in empirical models for landslide susceptibility. Such latitude offers plenty of opportunity for wasting time. Our choice of predictors is guided by physically based models of soil failure.

-   [Which attributes can be measured over the area of western Oregon where the model must be applied?]{.underline} Any predictors used must be obtainable from data sets with consistent state-wide coverage. Topographic attributes are calculated from lidar DEMs, which are available for almost the entire area. Datasets for substrate (geology) and land cover are available, but at lower spatial resolution than the DEMs.

-   [At what spatial scale should the attributes be measured?]{.underline} The length over which measurements of landscape attributes can be made is constrained by the spatial grain of available data. Within those constraints, measurements should be made at length scales appropriate for the physical processes driving soil failure. Lidar DEMs provide point measures of elevation over approximately a one-meter grid spacing. Measures of topographic attributes can therefore be made from a length of several meters, spanning two to three DEM points, to any longer length desired. The value measured will vary with the length over which it is measured. Consider gradient: measurements over several meters will resolve the effect of tree-fall pits. Measurements over tens of meters will miss the pits, but will resolve changes in gradient associated with bedrock hollows. Measurements over hundreds of meters will resolve influence of large headwalls. A length scale that is too small will resolve changes in gradient not associated with landslide locations, thus adding noise to the data; a length scale too large will miss the topographic features associated with individual landslides.

### Which Attributes?

Conceptually, soil on a hillslope will slide downslope when the gravitational force acting to move it downslope exceeds the forces acting to hold it in place. The physical details are complex, but geotechnical engineers have abstracted these details into relatively simple models that are remarkably successful at describing observed soil failures. These simple models guide our choice of predictors. The "infinite slope" model [@Skempton1957] is the starting point for many physically based models of soil failure, such as STALSTAB [@montgomery1994a]. Forces are calculated for a column of soil overlying a competent substrate. The weight per unit area of the column (weight equals column depth times soil bulk density) times the sine of the slope angle gives the force acting to move the column downslope. Frictional resistance, intrinsic soil cohesion, and the network of plant roots connecting the column to the substrate act to hold the column in place. Water filling the void spaces between soil particles reduces frictional resistance to an amount proportional to the depth of saturation.

Even for this simple model, we cannot measure all the variables required to calculate these forces (soil depth, friction angle, cohesion, saturation depth), but we can measure the topographic and land cover attributes that influence these variable values. Slope gradient can be obtained directly from a DEM. Field surveys find that soil depth correlates with slope and topographic curvature [@patton2018a]. During a rainstorm, infiltrating water flows downslope through the soil layer. The volume of water flowing through a column of soil increases during the storm as infiltrating water from further and further upslope reaches the column. That volume is determined by the area from which infiltrating water reaches the soil column (the contributing area) and the rainfall intensity (depth per unit time). The contributing area, and the corresponding depth of saturation, increases during the storm at a rate dependent on rainfall intensity and upslope topography. The velocity with which water flows through the soil increases as slope gradient increases. We can use the spatial variation in upslope gradient and aspect to calculate the size of the contributing area to a column of soil over time. Spatial variation in contributing area translates to spatial variation in saturation depth [e.g., @iida1999]. Thus, based on this simple model, the spatial distribution of three topographic attributes is related to the potential for landslide initiation: slope gradient, curvature, and aspect. These can all be calculated using a DEM.

Soil strength, in terms of frictional resistance and cohesion, are related to the texture (size distribution and shape of soil particles) and its mineralogy. These properties are in turn related to the type of rock the soil originates from. Spatial variation in rock type may thus also be related to spatial variation in landslide potential. DOGAMI provides statewide GIS data for geologic mapping (<https://www.oregongeology.org/geologicmap/index.htm>). This is a compilation of many different data sources.

The degree to which plant roots might act to anchor the soil to the underlying substrate and adjacent soil depends on the number and strength of those roots [e.g., @sidle1991a; @schmidt2001]. Numerous studies have reported accelerated landslide rates after timber harvest [e.g., @swanston1976; @wolfe1986a] and reductions in harvest-associated increases in rate with changes in harvest practices [@woodward2023]. We can expect, therefore, that some measure of stand characteristics might be associated with landslide rate. In our analysis of the 1996 storm data, Kelly and I found an association with stand age [@miller2007]. Turner et al. [-@turner2010a] also found systematic differences in landslide density with stand age. Schmidt et al. [-@schmidt2001] warn that effective root strength may not uniformly improve with stand age, but we need to work with some measure of stand conditions that can be consistently measured over all of Oregon. The Landscape Ecology, Modeling, Mapping & Analysis project ([LEMMA](https://lemma.forestry.oregonstate.edu/data/home)) provides [stand-structure maps](https://lemmadownload.forestry.oregonstate.edu/) that include "Basal area weighted stand age based on dominant and codominant trees" for Oregon. There are a variety of other metrics available, but so far stand age is the only one we have evaluated. However, for the PFA analysis, we want to use predictors that do not change over time, at least over the time frame of a harvest rotation, so stand age is not included in the model used for PFA.

As mentioned above, soil depth is an important factor affecting failure potential. Another process that affects soil depth, particularly along the axis of a topographic hollow, is the frequency of debris-flow scour. Depending on storm characteristics, landslides may be triggered at different locations points up or downslope along a hollow axis [@dunne1991]. The subsequent debris flow can scour the downslope portion of the hollow axis to bedrock. Soil then accumulates within the scoured zone over time [@dietrich1982; @may2003] until, at some point, it is deep enough to fail again. A debris-flow triggered far upslope along a hollow axis will thus reduce the potential for subsequent landslides downslope for the time it takes soil to accumulate to sufficient depth to become unstable during a storm. Thus, the potential for landslide initiation along a hollow axis is presumably a function of the frequency with which it is scoured by debris flows. We cannot measure this frequency directly, but we might find a topographic proxy. The frequency of debris-flow traversal is a function of the number of upslope landslide sources. In steep terrain, the number of landslide sources increases with upslope contributing area. This refers to total contributing area, measured to the drainage divide, not that associated with a particular storm duration. Total contributing area can also be measured as a function of the upslope distribution of slope aspect, which we obtain from a DEM.

Forest roads alter hillslope topography, locally increasing slope gradient on cut and sidecast slopes and altering drainage patterns by redirecting surface and shallow subsurface flows of water. Both effects can change the potential for soil failure, so proximity to a road may also be associated with increases in landslide density, as found in numerous studies [@Amaranthus1985; @Gucinski2001; @miller2007]. Distance to a road is an attribute we can examine, but because new roads are built and existing road conditions evolve over time, we will not include it in the model used for the PFA analysis.

### Algorithms for Topographic Attributes

We identified slope gradient, curvature, and contributing area as potentially informative predictors for landslide density. These can be calculated from the gridded elevation data provided by a DEM. We must select the length over which these values will be measured and the algorithms for calculating those values [@newman2022]. Both choices affect the degree to which the surface inferred from the elevation values is smoothed and the scale of landform features that can be resolved. Smoothing allows us to ignore both features too small to influence landslide potential and noise in the DEM data. Lidar DEMs are derived from the point cloud of reflections obtained from an aerial (airplane-mounted) laser signal. The point cloud includes reflections from the ground surface and the vegetation above it. For any signal, the reflection with the longest return time is interpreted as a [ground return](https://pro.arcgis.com/en/pro-app/latest/help/data/las-dataset/what-is-lidar-.htm). The elevations of the ground-return points are then interpolated to a regular grid to produce a DEM. However, not all last returns are from the ground, some signals may not penetrate through the vegetation so the last return is above the ground. This results in a variable spatial density of ground returns and some reflections from vegetation incorrectly interpreted as ground returns. We want to measure gradient and curvature over a length scale sufficiently long that these errors will have minimum effect.

High-resolution lidar DEMs can potentially resolve features on the ground spanning only a few meters. This will include the head scarps and scars of the mapped landslides and debris flows in our landslide inventories. Our interest, however, is in the pre-failure topography; if the initiation point is associated with the gradient of the head scarp, we will over-estimate the gradient associated with that landslide initiation point. So we want to chose a length scale sufficient long to smooth out features like shallow-landslide headscarps, but still sufficiently short that the hollow the headscarp might be located in is well characterized.

To calculate elevation derivatives from a DEM requires that the shape of the ground surface be inferred from the grid of elevation points. Generally, a smooth surface is fit to the points in the neighborhood of a central point and gradient and curvature for that central point are obtained from the equation for that surface. Polynomial equations are typically used to describe that surface, from planar to third order [@Florinsky2016]. The method used here is as follows. For each DEM grid point, elevations are obtained for the point and at eight equally spaced points along the circumference of a circle centered over that point. The diameter of that circle indicates the length scale of measurements. Elevations along the circumference are obtained using binomial interpolation from the four surrounding grid points. These nine elevation values are then used with equations derived by Zevenbergen and Thorne [@zevenbergen1987], modified for use with a circle [@shi2007]. The resulting surface intersects those nine points and varies smoothly between them. Gradient, curvature, and aspect for the central point are then obtained from derivatives of the equation for that surface.

We used a circle diameter of 15 meters. This is short enough to resolve small hollows and swales and (we think) for measuring the degree of topographic confinement along debris-flow corridors. It is also short enough that a 2-meter headscarp will produce about a 10% change in measured gradient. We do not currently have an estimate of the degree to which post-failure topography biases measures of topographic derivatives associated with landslide initiation locations. We have not yet performed a detailed sensitivity analysis to examine this issue. With advent of landslide inventories based on lidar differencing [@bernard2021], this question can be addressed directly.

To calculate contributing area, the ground surface is parsed into square horizontal cells associated with each DEM point. The flow that surface water would take over the ground surface is then proportioned from cell to cell. There are a variety of algorithms for this [@wilson2008], of which D-infinity [@tarboton1997b] is considered one of the best performing [@riihim√§ki2021a]. D-infinity accommodates downslope dispersion by distributing flow to two of the downslope cells. Recursive iteration following flow paths through the DEM is then used to sum inputs from all upslope cells. The resulting contributing area to a DEM cell then indicates the cumulative area of all upslope cells that contribute flow to the cell. This contributing area also applies for water infiltrating the soil during rainstorms, assuming that flow through the soil follows similar flow paths as surface water. To calculate the area contributing shallow subsurface flow to a DEM cell during a rainstorm, we must account for the velocity with which water flows through the soil. This velocity is determined as the Darcy velocity $V_D$

$$
V_D = K\sin(\theta)\cos(\theta)
$$ {#eq-Darcy}

where $K$ is the saturated hydraulic conductivity and $\theta$ is the hillslope gradient. @eq-Darcy gives the flow velocity measured horizontally, assuming that the direction of shallow subsurface flow through the soil is parallel to the surface. Looking upslope from a DEM cell, we find which cells contribute flow to that cell and calculate the time for flow from the upslope to the downslope cell using @eq-Darcy. This step is repeated moving upslope cell by cell until the cumulative travel time along a flow path equals the target duration. All the cells traversed then define the contributing area to the starting cell for that storm duration.

Saturated hydraulic conductivity for porous soils is on the order of one meter per hour (<https://structx.com/Soil_Properties_007.html>). Using that value, @fig-PCA shows how the pattern of high and low contributing area changes over time. Each map shows contributing area in DEM cells with a linear color ramp scaled from a value of one cell (the minimum) to the mean plus one standard deviation in contributing-area values. This provides a consistent scale for visually comparing the results.

![Partial contributing area calculated for a small drainage in the Siuslaw Basin.](images/PCA.jpg){#fig-PCA fig-align="center"}

A high-intensity short-duration storm will produce similar levels of soil saturation across all hillslopes. As the level of saturation is a function of both contributing area and intensity, if the intensity is high enough to trigger landslides, these may occur over a broad area. During a longer duration storm, the highest levels of soil saturation become concentrated along hollow and swale axes. Thus landslides are more likely to be triggered in those zones. It is well recognized that landslide potential increases with increasing rainfall intensity [e.g., @turner2010a]; these results suggest that landslide locations may vary with storm duration. We use the calculated contributing area for several different storm durations as predictors for landslide initiation.

The total contributing area to a DEM cell, that which would occur during an infinite duration storm, is shown in @fig-logaccum below. This map shows the maximum contributing area within a 7.5-meter radius of each DEM point. The largest contributing areas are far larger than those illustrated in @fig-PCA and increase monotonically downslope.

![Total contributing area.](images/logaccum.jpg){#fig-logaccum fig-align="center" width="6in"}

# Data

## DOGAMI inventory.

Landslide locations in the ODF 1996 Storm Study and DOGAMI Special Paper 53 inventories are shown in @fig-sites below. The 1996 inventory was based on field-based censuses of landslides within delineated study areas following storms in February and November. The DOGAMI inventory includes landslides associated with the 1996 storms, but also more recent events up to 2011.

![DOGAMI and ODF 1996-Storm landslide inventory sites](images/LandslideSites.png){#fig-sites fig-align="center" width="6in"}

The DOGAMI inventory has more landslides than the 1996 inventory and it spans a larger geographic and temporal range. Hence, it should provide a better sample of conditions where landslides occur across western Oregon than available from the 1996 inventory. There are two factors to consider when using estimates of initiation susceptibility based on these inventories.

-   [How well the inventory reflects the actual set of landslide scars and runout tracks that exist within the study area.]{.underline} Measures of susceptibility are based on measures of landslide density. Density is typically reported in terms of number per unit area, but may also be measured as landslide area or volume per unit area and as runout-track length per unit area or per unit channel length. If the inventory does not include all the landslides that exist within the study area, measures of density will be too small. If the missing landslides tend to occur in particular terrain locations, then resulting measures of spatial variation in landslide density and susceptibility will be biased. Inventories based on mapping of landslide scars from aerial photographs suffer from detection bias: small landslides and landslides under forest canopy are less visible than large landslides and those in clear-cuts and young forests. This results in bias with lower apparent densities measured in older forests. This bias can be substantial. With the field-based inventory for the Mapleton study area in the ODF 1996 Storm Study, Robison et al. [-@robison1999] found a 1.9-fold difference in landslide density (#/area) between young (\<10 years, 21.1 landslides/square mile) and old (\>100 years, 11.2 landslides/square mile) forest stands. Mapping done from 1:6000-scale photos found a 20.7-fold difference (12.4/sq mile for young stands versus 0.6/sq mile for old stands); mapping done from 2:24,000-scale photos found a 17-fold difference (5.1 versus 0.3 per square mile). The photo-based inventories indicated a difference in landslide density between young and old stands ten times greater than the field-based inventory. This detection bias hinders attempts to quantify associations of forest stand characteristics with landslide density. Furthermore, if stand characteristics vary with terrain location (e.g., if older stands tend to be located in steeper terrain) or if landslide locations vary with stand characteristics (e.g., if landslides tend to occur further upslope in younger stands), then measured spatial variations in landslide density will be biased. Without a complete census of all landslides, this bias cannot be fully accounted for. Future studies using lidar-differencing to detect elevation changes associated with landslides may reduce detection bias.

-   [How well the inventory reflects the total population of potential landslides.]{.underline} Shallow landslide scars revegetate and infill with soil and organic debris and so become increasingly difficult to detect over time. Field evidence of shallow landslide scars may persist for only 10 to 30 years [@reid_dunne1996; @brardinoni2003a]. Thus, any inventory will include only those landslides that have been triggered by storms within some time period preceding data collection. Event-based inventories, such as the ODF 1996 Storm Study, limit data collection to landslides associated with specific storm events. Landslide inventories reflect the spatial variation in landslide density produced by the storms that triggered the landslides in the inventory. If different storms tend to trigger landslides in different terrain locations, as @fig-PCA above suggests, then the inventory will be biased to the spatial patterns in landslide density produced by the sequence of storms preceding data collection for the inventory. The greater the time period spanned by the inventory, the more types of storms likely to be included. The ODF 1996 Storm Study inventory reflects landslide locations associated with the 1996 storms. The DOGAMI inventory includes landslides over a larger time span, from 1996 through 2011.

The ODF 1996 Storm Study provided a complete census of landslides with runout to stream channels within well-defined areal boundaries so that landslide density could be calculated from those data. The DOGAMI inventory, in contrast, uses a serendipitous sample from multiple studies without any defined study-area boundary. To use the DOGAMI inventory within a density context, we needed to delineate some area local to the mapped landslides within which we were confident there were no other landslide scars visible. For this we followed a strategy described by Zhu et al. [-@zhu2017; see also @nowickijessee2018a] for sampling areas affected by liquifaction during an earthquake. They also had mapped locations of events but lacked a delimited boundary within which all events were mapped. They assumed that, for each mapped event location, that if any other events had occurred in the near vicinity, that those other events would have also been mapped. For the DOGAMI landslide inventory, we assume that if another landslide were visible with 250 meters of any included landslide, that it would have been mapped as well. So we extended a 250-meter buffer around each mapped landslide point which then defined our study area. Terrain characteristics associated with mapped landslide and nonlandslide points were determined from within these buffer areas. This gave us a well-defined area from which to measure changes in landslide density with terrain attributes. Had we used a larger buffer our areas would be larger and the resulting densities lower. However, the resulting spatial variability in landslide susceptibility depends only on differences in density from point to point, not on the magnitude.

The ODF 1996 Storm Study field surveys identified landslides by walking all streams, up to a gradient of 40%, locating all recent landslide deposits within the streams, and following the runout track to the landslide initiation point. The DOGAMI inventory includes only landslides with mapped runout extent. Thus, both inventories are focused on landslides with some degree of runout, although they are probably sampling different portions of the total population of such landslides. For their inventory, DOGAMI identified landslides with mapped runout from previous studies, including the ODF 1996 Storm Study, and digitized the initiation point and runout extent using current lidar-derived base maps in conjunction with aerial photographs. Thus, the initiation points should be accurately and precisely located on the lidar DEMs. Runout tracks were digitized in the same manner. Because runout tracks for the DOGAMI inventory were based on photo interpretation, the extent of runout may be under estimated. Comparison with the field-mapped runout extent from the ODF 1996 Storm Study is hindered by the 1:24,000-scale topographic base maps used for digitizing and because field interpretations were based on "debris-torrent" effects rather than debris-flow effects. The debris-torrent-mapped impacts may have included effects of hyperconcentrated flow, dam-break floods, and moving organic dams, which extend further downstream than debris-flow deposits. There are many potentially confounding factors that can affect model results. It is worthwhile to keep these in mind when interpreting these data sets.

Balanced or unbalanced sample.

Plots of landslide density and log(odds) versus predictors.

```{r}
grad <- read.csv("c:/work/data/pfa/den_gradient.csv")
n <- nrow(grad)
grad$propArea <- grad$sumArea / grad$sumArea[[n]]
grad$propLS <- grad$sumLS / grad$sumLS[[n]]

coef <- grad$sumLS[[n]] / grad$sumArea[[n]]
ggplot(data = grad, aes(x = val, y = sumLS)) +
       theme_bw() +
       geom_line(color = "black", linewidth = 0.5) +
       geom_point(aes(color = val), shape = 16, size = 4) +
       geom_line(aes(x = val, y = sumArea*coef), color = "black", linewidth = 0.5) +
       geom_point(aes(x = val, y = sumArea*coef, color = val), shape = 17, size = 3) +
       scale_y_continuous(name = "Landslides", sec.axis = sec_axis(~./coef, name = "Area (sq km)")) +
       scale_color_continuous_sequential(palette = "Viridis") +
       labs(title = "Cumulative distributions",
            subtitle = "Basin area and number of landslides vs gradient",  
            x = "Gradient",
            y = "Proportion",
            color = "Gradient") +
       annotate("text", x = .3, y = 450, label = "Area") +
       annotate("point", shape = 2, size = 3, x = .45, y = 450) +
       annotate("text", x = .3, y = 430, label = "Landslides") +
       annotate("point", shape = 1, size = 4, x = .45, y = 430)
```

```{r}
ggplot(data = grad, aes(x = sumArea, y = sumLS, color = val)) +
        theme_bw() +
        geom_line(color = "black", linewidth = 0.5) +
        geom_point(shape = 16, size = 3) +
        scale_color_continuous_sequential(palette = "Viridis") +
        labs(title = "Cumulative Number of Landslides vs Cumulative Area",
             subtitle = "Ordered by Increasing Gradient",
             x = "Area (sq km)", 
             y = "Number of Landslides",
             color = "Gradient")
```

```{r}
ggplot(data = grad, aes(x = val, y = density)) +
  geom_point(fill = "gray", color = "black", shape = 21, size = 3, alpha = 0.5) +
  labs(title = "Landslide Density vs Gradient", 
       x = "Gradient",
       y = "Landslide Density (#/cell)",
       fill = "Gradient")
```

```{r}
ggplot(data=grad, aes(x=val, y=log_odds)) + 
  geom_point(shape = 21, size=2.5, color="black", fill="gray", alpha=0.5) + 
  stat_smooth(color="black", method = "lm", formula = y~ x + I(x^2)) + 
  stat_smooth(color="red", method = "lm", formula = y ~ x) +
  labs(title = "Log(odds) vs Gradient",
       subtitle = "Exhibits a nonlinear relationship",
       x = "Gradient", 
       y = "Log(odds) of an initiation point within a DEM cell") +
  annotate("segment", x=0.34, xend=0.5, y=-8, yend = -8, color = "red", linewidth=1.3) +
  annotate("text", x=0.6, y=-8, label="Linear") +
  annotate("segment", x = 0.34, xend = 0.5, y = -8.25, yend = -8.25, color = "black", linewidth = 1.3) +
  annotate("text", x = 0.62, y = -8.25, label = "Quadratic" )
```

```{r}
pca48 <- read.csv("c:/work/data/pfa/den_pca48.csv")

ggplot(data=pca48, aes(x=val, y=log_odds)) + 
  geom_point(shape = 21, size=2.5, color="black", fill="gray", alpha=0.5) + 
  ylim(-13.5,-5.5) +
  stat_smooth(color="black", method = "lm", formula = y~ x + I(x^2)) + 
  stat_smooth(color="red", method = "lm", formula = y ~ x) +
  labs(title = "Log(odds) vs Contributing Area",
       subtitle = "Also nonlinear",
       x = "Contributing Area (DEM cells) 48 hr duration", 
       y = "Log(odds) of an initiation point within a DEM cell") +
  annotate("segment", x=5, xend=10, y=-6.5, yend = -6.5, color = "red", linewidth=1.3) +
  annotate("text", x=13, y=-6.5, label="Linear") +
  annotate("segment", x = 5, xend = 10, y = -6.8, yend = -6.8, color = "black", linewidth = 1.3) +
  annotate("text", x = 13, y = -6.8, label = "Quadratic" )
```

```{r}
tancurv <- read.csv("c:/work/data/pfa/den_tancurv.csv")

ggplot(data=tancurv, aes(x=val, y=log_odds)) + 
  geom_point(shape = 21, size=2.5, color="black", fill="gray", alpha=0.5) + 
  ylim(-13, -5) +
  stat_smooth(color="black", method = "lm", formula = y~ x + I(x^2)) + 
  stat_smooth(color="red", method = "lm", formula = y ~ x) +
  labs(title = "Log(odds) vs Tangential curvature",
       subtitle = "Also nonlinear",
       x = "Tangential Curvature", 
       y = "Log(odds) of an initiation point within a DEM cell") +
  annotate("segment", x=-0.07, xend=-0.03, y=-6.5, yend = -6.5, color = "red", linewidth=1.3) +
  annotate("text", x=-0.01, y=-6.5, label="Linear") +
  annotate("segment", x = -0.07, xend = -0.03, y = -6.8, yend = -6.8, color = "black", linewidth = 1.3) +
  annotate("text", x = -0.01, y = -6.8, label = "Quadratic" )
```

```{r}
n <- nrow(pca48)
pca48$propArea <- pca48$sumArea / pca48$sumArea[[n]]
pca48$propLS <- pca48$sumLS / pca48$sumLS[[n]]

coef <- pca48$sumLS[[n]] / pca48$sumArea[[n]]
ggplot(data = pca48, aes(x = val, y = sumLS)) +
       theme_bw() +
       geom_line(color = "black", linewidth = 0.5) +
       geom_point(aes(color = val), shape = 16, size = 4) +
       geom_line(aes(x = val, y = sumArea*coef), color = "black", linewidth = 0.5) +
       geom_point(aes(x = val, y = sumArea*coef, color = val), shape = 17, size = 3) +
       scale_y_continuous(name = "Landslides", sec.axis = sec_axis(~./coef, name = "Area (sq km)")) +
       scale_color_continuous_sequential(palette = "Viridis") +
       labs(title = "Cumulative distributions:\nproportion of area and landslides vs contributing area",  
            x = "Contributing Area (DEM cells, 48-hour duration)",
            y = "Proportion",
            color = "Contributing\nArea") +
       annotate("text", x = 5, y = 450, label = "Area") +
       annotate("point", shape = 2, size = 3, x = 10, y = 450) +
       annotate("text", x = 5, y = 430, label = "Landslides") +
       annotate("point", x = 10, y = 430, shape = 1, size = 4)
```

```{r}
ggplot(data = pca48, aes(x = sumArea, y = sumLS, color = val)) +
        theme_bw() +
        geom_line(color = "black", size = 0.5) +
        geom_point(shape = 16, size = 3) +
        scale_color_continuous_sequential(palette = "Viridis") +
        labs(title = "Cumulative Number of Landslides vs Cumulative Area",
             subtitle = "Ordered by Contributing Area",
             x = "Area (sq km)", 
             y = "Number of Landslides",
             color = "Contributing\nArea")
```

```{r}
ggplot(data = pca48, aes(x = val, y = )) +
  geom_point(aes(x = val, y = density), fill = "gray", color = "black", shape = 21, size = 3, alpha = 0.5) +
  labs(title = "Landslide Density vs Contributing Area", 
       x = "Contributing Area in cells, 48-hour duration",
       y = "Landslide Density (#/cell)",
       fill = "Contributing\nArea")
```

```{r}
ggplot(data=pca48, aes(x=val, y=log_odds)) + 
  geom_point(shape = 21, size=2.5, color="black", fill="gray", alpha=0.5) + 
  ylim(-13.5,-5.5) +
  stat_smooth(color="black", method = "lm", formula = y~ x + I(x^2)) + 
  stat_smooth(color="red", method = "lm", formula = y ~ x) +
  labs(title = "Log(odds) vs Contributing Area",
       subtitle = "Exhibits a nonlinear relationship",
       x = "Contributing Area (DEM cells) 48 hr duration", 
       y = "Log(odds) of an initiation point within a DEM cell")
```

```{r}
# 2d plots
areaxy <- read.csv("c:/work/data/pfa/denGradPCA10_area0.csv")
lsxy <- read.csv("c:/work/data/pfa/denGradPCA10_ls0.csv")
denxyz <- read.csv("c:/work/data/pfa/denGradPCA10_den.csv")
areaplot <- ggplot(areaxy, aes(x,y)) +
  geom_bin2d(bins=500) + 
  xlim(0,1.3) + 
  ylim(0,60)
```

```{r}
areaplot + scale_fill_distiller(palette="Spectral") + 
  geom_point(data=lsxy, aes(x,y,color="black"), size=1) + 
  geom_density2d(data=lsxy, aes(x,y), color="black") + 
  theme_bw() + 
  labs(x = "Gradient (rise/run)", y = "48-hr Contributing Area (DEM cells)", fill = "DEM-cell\ncount") +
  scale_color_identity(name="",guide="legend",labels="DOGAMI\nInitiation\nPoint")
```

```{r}
# 2d plots
areaxy <- read.csv("c:/work/data/pfa/denGradtan10a_area0.csv")
lsxy <- read.csv("c:/work/data/pfa/denGradtan10a_ls0.csv")
denxyz <- read.csv("c:/work/data/pfa/denGradtan10a_den.csv")
areaplot <- ggplot(areaxy, aes(x,y)) +
  geom_bin2d(bins=500) +
  xlim(0.2, 1.3) +
  ylim(-0.2, 0.2)
```

```{r}
areaplot + scale_fill_distiller(palette="Spectral") + 
  geom_point(data=lsxy, aes(x,y,color="black"), size=1) + 
  theme_bw() + 
  labs(x = "Gradient (rise/run)", y = "Tangential Curvature", fill = "DEM-cell\ncount") +
  scale_color_identity(name="",guide="legend",labels="DOGAMI\nInitiation\nPoint")
```

```{r}
denxyz <- read.csv("c:/work/data/pfa/denGradtan10_den.csv")
ggplot(denxyz, aes(x,y)) + 
  geom_tile(aes(x,y,z=z,fill=z)) +
  geom_point(data=lsxy, aes(x,y)) +
  xlim(0.2, 1.3) +
  ylim(-0.2,0.2) +
  scale_fill_distiller(palette="Spectral") +
  labs(x="Gradient (rise/run)", y="Tangential Curvature")
  
```

```{r}
areaden <- ggplot(areaxy, aes(x,y)) + stat_density_2d(aes(fill = after_stat(density)), geom = "raster", contour = FALSE)
```

```{r}

```
